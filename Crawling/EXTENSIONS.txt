This solution could easily be applied to domains outside of Amazon, but it would take a bit of research to determine what type of data was being sought and how it was built. The URL's would need to be updated for navigation purposes and the crawling function would need to be edited for the change in data types and collection methods.  With that said, the same techniques used in this solution should easily be adapted to a vast number of websites and data-structures as it uses the same classes, id's and selectors that are used when putting web apps together.  The only issues that you could run into, and it was definitely an issue here, is trying to capture data that isn't cataloged or referenced clearly.  But I feel it is an issue that could be solved fairly quickly.

The same goes for products other than books.  If you wanted to collect data on shoes, electronics, food, houses, cars, etc., this solution could be adapted to just about any product as they all have a lot of the same attributes (names, descriptions, pricing just to name a few).  Again, there would need to be a little research done into how things are listed/built, there would need to be a little editing done on the crawl function and you could potentially have the same issues as listed above with poorly referenced data, but I now feel all data listed on publicly accessible websites should be pretty straight-forward and simple to capture (especially for anyone who does it regularly!).